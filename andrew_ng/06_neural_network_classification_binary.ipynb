{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "def g_sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def g_sigmoid_derivative(z):\n",
    "    return g_sigmoid(z) * (1 - g_sigmoid(z))\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def hypothesis_neural(neural_model, input_data):\n",
    "    a_l = input_data\n",
    "    \n",
    "    for l in range(neural_model.shape[0]):\n",
    "        z_lp1 = neural_model[l].dot(a_l)\n",
    "        a_lp1 = g_sigmoid(z_lp1)\n",
    "        \n",
    "        if l != neural_model.shape[0] - 1:\n",
    "            a_lp1 = np.concatenate((np.array([1]), a_lp1))\n",
    "            \n",
    "        a_l = a_lp1\n",
    "        \n",
    "    return a_l[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def unroll_matrix(matrix):\n",
    "    return matrix.ravel()\n",
    "\n",
    "def unroll_matrix_array(matrix_vec):\n",
    "    unrolled = np.array([])\n",
    "    for matrix in matrix_vec:\n",
    "        unrolled = np.concatenate((unrolled, unroll_matrix(matrix)), axis=None)\n",
    "        \n",
    "    return np.array(unrolled).ravel()\n",
    "\n",
    "def roll_vec_to_matrix(vec, matrix_size):\n",
    "    rows = matrix_size[0]\n",
    "    cols = matrix_size[1]\n",
    "    \n",
    "    if vec.shape[0] != rows * cols:\n",
    "        raise ValueError(f'Nekorektno razvijanje vektora velicine {vec.shape[0]} u matricu'\n",
    "                         f' dimenzija {rows}x{cols} (matrica od {rows*cols} elemenata)')\n",
    "    \n",
    "    matrix = np.zeros(matrix_size)\n",
    "    for i in range(rows):\n",
    "        matrix[i] = vec[i*cols : (i + 1)*cols]\n",
    "        \n",
    "    return matrix\n",
    "\n",
    "def roll_vec_to_matrix_array(long_vec, matrix_sizes):\n",
    "    matrix_array = []\n",
    "    prev_rows = 0\n",
    "    prev_cols = 0\n",
    "    \n",
    "    for matrix_size in matrix_sizes:\n",
    "        rows = matrix_size[0]\n",
    "        cols = matrix_size[1]\n",
    "        \n",
    "        i = prev_rows * prev_cols\n",
    "        j = rows * cols\n",
    "        matrix_array.append(roll_vec_to_matrix(long_vec[i : i+j], matrix_size))\n",
    "        \n",
    "        prev_rows = rows\n",
    "        prev_cols = cols\n",
    "        \n",
    "    return np.array(matrix_array)\n",
    "\n",
    "def get_matrix_sizes(matrix_array):\n",
    "    sizes = []\n",
    "    for i in range(matrix_array.shape[0]):\n",
    "        sizes.append(matrix_array[i].shape)\n",
    "        \n",
    "    return sizes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def regularization(neural_model, N_set_size, lambda_param=0):\n",
    "    if lambda_param == 0:\n",
    "        return 0\n",
    "    \n",
    "    reg = 0\n",
    "    for l in range(neural_model.shape[0]):\n",
    "        for i in range(neural_model[l].shape[0]):\n",
    "            for j in range(1, neural_model[l].shape[1]):\n",
    "                reg += (neural_model[l][i][j])**2\n",
    "                \n",
    "    return lambda_param * reg / (2*N_set_size)\n",
    "\n",
    "def loss_logistic(X, y, neural_model, lambda_param=0):\n",
    "    N = y.shape[0]\n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(N):\n",
    "        y_i = y[i][0]\n",
    "        y_i_predict = hypothesis_neural(neural_model, X[i])\n",
    "        \n",
    "        loss += y_i*np.log(y_i_predict) + (1 - y_i)*np.log(1 - y_i_predict)\n",
    "        \n",
    "    return -loss / N + regularization(neural_model, N, lambda_param)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "def gradient_checking(X, y, neural_model, lambda_param=0, eps=10e-4):\n",
    "    w_unrolled = unroll_matrix_array(neural_model)\n",
    "    n = len(w_unrolled)\n",
    "    \n",
    "    grad_approx = np.zeros((n,))\n",
    "    matrix_sizes = get_matrix_sizes(neural_model)\n",
    "    \n",
    "    for i in range(n):\n",
    "        # OBAVEZNO MORA KOPIJA VEKTORA, inace imamo dve reference na isti vektor!!!\n",
    "        w_plus = w_unrolled.copy()\n",
    "        w_minus = w_unrolled.copy()\n",
    "        w_plus[i] += eps\n",
    "        w_minus[i] -= eps\n",
    "        \n",
    "        # print('w_plus:')\n",
    "        # print(w_plus)\n",
    "        # \n",
    "        # print('\\nw_minus:')\n",
    "        # print(w_minus)\n",
    "        # \n",
    "        # print(f'w_plus == w_minus?\\n{w_plus == w_minus}')\n",
    "        \n",
    "        w_plus_rolled = roll_vec_to_matrix_array(w_plus, matrix_sizes)\n",
    "        w_minus_rolled = roll_vec_to_matrix_array(w_minus, matrix_sizes)\n",
    "        \n",
    "        loss_plus = loss_logistic(X, y, w_plus_rolled, lambda_param)\n",
    "        loss_minus = loss_logistic(X, y, w_minus_rolled, lambda_param)\n",
    "        \n",
    "        # print(f'loss_plus_{i} = {loss_plus}')\n",
    "        # print(f'loss_minus_{i} = {loss_minus}\\n')\n",
    "        \n",
    "        grad_approx[i] = (loss_plus - loss_minus) / (2*eps)\n",
    "    \n",
    "    return grad_approx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def gradient_descent(X, \n",
    "                     y, \n",
    "                     neural_network, \n",
    "                     alpha=0.01, \n",
    "                     num_iter=1000, \n",
    "                     lambda_param=0,\n",
    "                     plot=False):\n",
    "    \n",
    "    loss_history = np.zeros((num_iter, 1))\n",
    "    matrix_sizes = get_matrix_sizes(neural_network.model)\n",
    "    \n",
    "    # Podsetnik: neuralna mreza prilikom kreiranja vec ima inicijalni model.\n",
    "    # Ovde je dovoljno samo da ga razvijemo u vektor kako bi ga pripremili za\n",
    "    # algoritam gradijentnog spusta\n",
    "    w = neural_network.unroll_model()\n",
    "    for i in range(num_iter):\n",
    "        loss, gradient = neural_network.backward_propagation(X, y, lambda_param)\n",
    "        w = w - alpha * gradient\n",
    "        \n",
    "        # VRLO VAZAN KORAK: nakon sto je model azuriran, treba ga azurirati UNUTAR neuralne\n",
    "        # mreze kako bi backward propagation algoritam radio sa novim vrednostima modela.\n",
    "        neural_network.set_model(roll_vec_to_matrix_array(w, matrix_sizes))\n",
    "        \n",
    "        loss_history[i] = loss\n",
    "    \n",
    "    if plot:\n",
    "        plt.plot(range(num_iter), loss_history)\n",
    "        \n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(['Loss_train'])\n",
    "            \n",
    "    return loss_history, w"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_layer_size, hidden_layer_options, output_layer_size, eps=10e-3):\n",
    "        self.input_layer_size = input_layer_size\n",
    "        self.hidden_layers_num = len(hidden_layer_options)\n",
    "        self.layers_num = self.hidden_layers_num + 2\n",
    "        self.output_layer_size = output_layer_size\n",
    "        self.layer_sizes = [input_layer_size] + hidden_layer_options + [output_layer_size]\n",
    "        self.layer_indices = range(self.layers_num)\n",
    "        \n",
    "        # NAPOMENA: velicina slojeva neuralne mreze (layer_sizes) se racuna kao broj jedinica\n",
    "        # BEZ bias jedinice, ali prilikom postavljanja slojeva mreza ocekuje bias jedinice.\n",
    "        # Dakle, svaki sloj je velicine za jedan vise, osim poslednjeg sloja.\n",
    "        layers = [np.ones(input_layer_size + 1)]\n",
    "        for i in range(self.hidden_layers_num):\n",
    "            layers.append(np.ones(hidden_layer_options[i] + 1))\n",
    "            \n",
    "        layers.append(np.ones(output_layer_size))\n",
    "        self.network = np.array(layers)\n",
    "        \n",
    "        # Cuvam dimenzije matrica Wij koje mapiraju slojeve j -> j + 1\n",
    "        # s(j+1) x (s(j) + 1)\n",
    "        mappers = {}\n",
    "        for l in range(self.layers_num - 1):\n",
    "           rows = self.layer_sizes[l + 1]\n",
    "           cols = self.layer_sizes[l] + 1\n",
    "           \n",
    "           mappers[l] = (rows, cols)\n",
    "        \n",
    "        self.layer_mapper_sizes = mappers\n",
    "        \n",
    "        # inicijalizacija modela, tj. matrica W_i za svaki sloj\n",
    "        ws = []\n",
    "        for l in range(self.layers_num - 1):\n",
    "            w_l = 2*eps * np.random.random(self.layer_mapper_sizes[l]) - eps\n",
    "            ws.append(w_l)\n",
    "            \n",
    "        self.model = np.array(ws)\n",
    "        self.model_trained = self.model\n",
    "        \n",
    "        # Analogno kao za slojeve, delte ocekuju bias jedinice, koje se NECE koristiti\n",
    "        # u proracunima backpropagation algoritma. Prvi sloj mora da ima\n",
    "        # podrazumevano za delte sve nule, jer ulazni podaci nemaju gresku.\n",
    "        deltas = []\n",
    "        for l in self.layer_indices:\n",
    "            if l == self.layers_num - 1:\n",
    "                delta_l = np.zeros(self.layer_sizes[l])\n",
    "            else:\n",
    "                delta_l = np.zeros(self.layer_sizes[l] + 1)\n",
    "                \n",
    "            deltas.append(delta_l)\n",
    "            \n",
    "        self.deltas = np.array(deltas)\n",
    "        \n",
    "    def __str__(self):\n",
    "        self.print_network()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        self.print_network()\n",
    "        \n",
    "    def __layer_index_check(self, layer_index):\n",
    "        if layer_index < 0 or layer_index >= self.layers_num:\n",
    "            raise IndexError(f'Nekorektan indeks sloja neuralne mreze {layer_index}: '\n",
    "                             f'dostupni indeksi 0-{self.layers_num - 1}')\n",
    "        \n",
    "    def set_layer(self, layer_index, units_vec):\n",
    "        self.__layer_index_check(layer_index)\n",
    "        \n",
    "        # poslednji sloj NEMA bias unit\n",
    "        # -1 jer mreza inicijalno ne sadrzi bias unit, a ja ocekujem vektor koji sadrzi bias unit\n",
    "        if layer_index != self.layers_num - 1 and \\\n",
    "                units_vec.shape[0] != self.layer_sizes[layer_index] + 1:\n",
    "            error_message = f'Nekorektna dimenzija vektora {units_vec.shape[0]} za sloj {layer_index}: ' \\\n",
    "                f'ocekivana {self.layer_sizes[layer_index] + 1}'\n",
    "            \n",
    "            raise ValueError(error_message)\n",
    "        elif layer_index == self.layers_num - 1 and \\\n",
    "                units_vec.shape[0] != self.layer_sizes[layer_index]: # ovde je layer_index poslednji sloj\n",
    "            error_message = f'Nekorektna dimenzija vektora {units_vec.shape[0]} za izlazni sloj {layer_index}: ' \\\n",
    "                f'ocekivana {self.layer_sizes[layer_index]}'\n",
    "            \n",
    "            raise ValueError(error_message)\n",
    "        \n",
    "        self.network[layer_index] = units_vec\n",
    "        \n",
    "    def set_all_layers(self, all_layers):\n",
    "        for l in range(self.layers_num):\n",
    "            self.set_layer(l, all_layers[l])\n",
    "            \n",
    "    def set_mapper(self, layer_index, mapper):\n",
    "        self.__layer_index_check(layer_index)\n",
    "        \n",
    "        if mapper.shape != self.model[layer_index].shape:\n",
    "            error_message = f'Nekorektna dimenzija matrice {mapper.shape[0]}x{mapper.shape[1]} ' \\\n",
    "                f'za preslikavanje sloja {layer_index} -> {layer_index + 1}: ocekivana ' \\\n",
    "                f'{self.model[layer_index].shape[0]}x{self.model[layer_index].shape[1]}'\n",
    "            \n",
    "            raise ValueError(error_message)\n",
    "        \n",
    "        self.model[layer_index] = mapper\n",
    "        \n",
    "    # Funkcija po analogiji za slojeve, radi doslednosti\n",
    "    def set_all_mappers(self, all_mappers):\n",
    "        for l in range(self.layers_num - 1):\n",
    "            self.set_mapper(l, all_mappers[l])\n",
    "            \n",
    "    def set_model(self, all_mappers):\n",
    "        self.set_all_mappers(all_mappers)\n",
    "        \n",
    "    def set_delta(self, layer_index, delta_vec):\n",
    "        self.__layer_index_check(layer_index)\n",
    "        \n",
    "        if layer_index != self.layers_num - 1 and \\\n",
    "                delta_vec.shape[0] != self.layer_sizes[layer_index] + 1:\n",
    "            error_message = f'Nekorektna dimenzija vektora {delta_vec.shape[0]}:' \\\n",
    "                f'ocekivana {self.layer_sizes[layer_index] + 1}'\n",
    "            \n",
    "            raise ValueError(error_message)\n",
    "        elif layer_index == self.layers_num - 1 and \\\n",
    "                delta_vec.shape[0] != self.layer_sizes[layer_index]:\n",
    "            error_message = f'Nekorektna dimenzija vektora {delta_vec.shape[0]} za poslednji sloj: ' \\\n",
    "                f'ocekivana {self.layer_sizes[layer_index]}' \n",
    "            \n",
    "            raise ValueError(error_message)\n",
    "            \n",
    "        self.deltas[layer_index] = delta_vec\n",
    "        \n",
    "    def set_all_deltas(self, all_deltas):\n",
    "        for l in self.layer_indices:\n",
    "            self.set_delta(l, all_deltas[l])\n",
    "        \n",
    "    def unroll_mapper(self, layer_index):\n",
    "        self.__layer_index_check(layer_index)\n",
    "        \n",
    "        return self.model[layer_index].ravel()\n",
    "    \n",
    "    def unroll_model(self):\n",
    "        unrolled_model = np.array([])\n",
    "        for l in range(self.layers_num - 1):\n",
    "            W_l = self.unroll_mapper(l)\n",
    "            unrolled_model = np.concatenate((unrolled_model, W_l), axis=None)\n",
    "            \n",
    "        return np.array(unrolled_model).ravel()\n",
    "    \n",
    "    @staticmethod\n",
    "    def __activate_layer(z_vec, activation_func):\n",
    "        return activation_func(z_vec)\n",
    "    \n",
    "    def forward_propagation(self, input_layer_data):\n",
    "        a_l = input_layer_data\n",
    "        self.set_layer(0, a_l)\n",
    "        \n",
    "        for l in range(self.layers_num - 1):\n",
    "            z_lp1 = self.model[l].dot(a_l) # z(l+1) = W(l)*a(l)\n",
    "            a_l = g_sigmoid(z_lp1)\n",
    "            \n",
    "            # Dodavanje bias jedinice u a_l vektor\n",
    "            if l != self.layers_num - 2:\n",
    "                a_l = np.concatenate((np.array([1]), a_l))\n",
    "            \n",
    "            self.set_layer(l + 1, a_l)\n",
    "            \n",
    "    # Vrsi propagaciju na osnovu prosledjenog modela, a ne na osnovu internog modela.\n",
    "    def propagate(self, input_layer_data, neural_model):\n",
    "        a_l = input_layer_data\n",
    "        self.set_layer(0, a_l)\n",
    "        \n",
    "        for l in range(self.layers_num - 1):\n",
    "            z_lp1 = neural_model[l].dot(a_l)\n",
    "            a_l = g_sigmoid(z_lp1)\n",
    "            \n",
    "            # Dodavanje bias jedinice u a_l vektor\n",
    "            if l != self.layers_num - 2:\n",
    "                a_l = np.concatenate((np.array([1]), a_l))\n",
    "            \n",
    "            self.set_layer(l + 1, a_l)\n",
    "            \n",
    "    def backward_propagation_deltas(self, y_data):\n",
    "        delta_output = self.network[self.layers_num - 1] - y_data\n",
    "        self.set_delta(self.layers_num - 1, delta_output)\n",
    "        \n",
    "        for l in range(self.layers_num - 2, 0, -1):\n",
    "            z_l = self.model[l - 1].dot(self.network[l - 1]) # z(l) = W(l-1)*a(l-1)\n",
    "            g_prim_vec = np.concatenate((np.array([1]), g_sigmoid_derivative(z_l)))\n",
    "            \n",
    "            if l + 1 == self.layers_num - 1:\n",
    "                delta_lp1 = self.deltas[l + 1] # ne postoji bias jedinica za poslednji sloj\n",
    "            else:\n",
    "                delta_lp1 = self.deltas[l + 1][1:] # ignorisem bias jedinicu delta vektora\n",
    "                \n",
    "            delta_l = self.model[l].transpose().dot(delta_lp1) * g_prim_vec\n",
    "            self.set_delta(l, delta_l)\n",
    "            \n",
    "        # delta_0 je uvek nula-vektor, postavljen jos prilikom inicijalizacije same mreze\n",
    "        \n",
    "    # Funkcija koja racuna uporedo parcijalne izvode (gradijent) i funkciju gubitka\n",
    "    def backward_propagation(self, X_training, y_training, lambda_param=0):\n",
    "        accs = []\n",
    "        for l in range(self.layers_num - 1):\n",
    "            delta_acc_l = np.zeros(self.layer_mapper_sizes[l])\n",
    "            accs.append(delta_acc_l)\n",
    "            \n",
    "        # Delta_l akumulatori za parcijalne izvode i inicijalni parcijalni izvodi\n",
    "        delta_accumulators = np.array(accs)\n",
    "        gradient = np.array(accs)\n",
    "        loss = 0\n",
    "        \n",
    "        N = X_training.shape[0]\n",
    "        for i in range(N):\n",
    "            self.forward_propagation(X_training[i]) # a_0 = X[i] ...\n",
    "            self.backward_propagation_deltas(y_training[i])\n",
    "            self.__accumulate_deltas(delta_accumulators)\n",
    "            \n",
    "            # print(f'Delta accumulators:')\n",
    "            # print(delta_accumulators)\n",
    "            \n",
    "            # Hocu da y_predict i y budu realne vrednosti a ne vektori velicine 1\n",
    "            y_i_predict = self.network[self.layers_num - 1][0]\n",
    "            y_i = y_training[i][0]\n",
    "            \n",
    "            loss += y_i*np.log(y_i_predict) + (1 - y_i)*np.log(1 - y_i_predict)\n",
    "            \n",
    "            # print(f'y_predict = {y_predict}, y_{i} = {y_i}')\n",
    "            # print(f'Loss_{i}: {loss}')\n",
    "            \n",
    "        self.__set_partial_derivatives(gradient, delta_accumulators, lambda_param)\n",
    "        loss = -loss / N + regularization(self.model, N, lambda_param)\n",
    "        \n",
    "        return loss, unroll_matrix_array(gradient)\n",
    "            \n",
    "    def __accumulate_deltas(self, delta_accumulators):\n",
    "        for l in range(self.layers_num - 1):\n",
    "            if l + 1 == self.layers_num - 1:\n",
    "                delta_lp1 = self.deltas[l + 1].reshape(-1, 1)\n",
    "            else:\n",
    "                delta_lp1 = self.deltas[l + 1][1:].reshape(-1, 1)\n",
    "                \n",
    "            a_l = self.network[l].reshape(-1, 1).transpose()\n",
    "\n",
    "            delta_accumulators[l] += delta_lp1.dot(a_l)\n",
    "            \n",
    "    def __set_partial_derivatives(self, partial_derivatives, delta_accumulators, lambda_param):\n",
    "        for l in range(self.layers_num - 1):\n",
    "            for i in range(self.model[l].shape[0]):\n",
    "                for j in range(self.model[l].shape[1]):\n",
    "                    if j == 0:\n",
    "                        partial_derivatives[l][i][j] = delta_accumulators[l][i][j] / N\n",
    "                    else:\n",
    "                        partial_derivatives[l][i][j] = delta_accumulators[l][i][j] / N + \\\n",
    "                                                       lambda_param * self.model[l][i][j]\n",
    "                        \n",
    "    def fit(self, X, y, alpha=0.01, num_iter=1000, lambda_param=0, plot=False):\n",
    "        loss_history, model_trained = gradient_descent(X, y, \n",
    "                                                       self, \n",
    "                                                       alpha, \n",
    "                                                       num_iter, \n",
    "                                                       lambda_param,\n",
    "                                                       plot=plot)\n",
    "        \n",
    "        matrix_sizes = list(self.layer_mapper_sizes.values())\n",
    "        self.model_trained = roll_vec_to_matrix_array(model_trained, matrix_sizes)\n",
    "            \n",
    "    def predict(self, input_data):\n",
    "        return hypothesis_neural(self.model, input_data)\n",
    "        \n",
    "    def print_layer(self, layer_index):\n",
    "        self.__layer_index_check(layer_index)\n",
    "        \n",
    "        print(f'Layer {layer_index}:')\n",
    "        print(self.network[layer_index])\n",
    "        \n",
    "    def print_network(self):\n",
    "        print('~ Neural network ~')\n",
    "        \n",
    "        for i in range(self.network.shape[0]):\n",
    "            print(f'Layer {i + 1}:')\n",
    "            print(self.network[i])\n",
    "            \n",
    "    def print_layer_mapper_sizes(self):\n",
    "        print('Dimenzije matrica modela koji mapiraju slojeve:')\n",
    "        \n",
    "        for k, v in self.layer_mapper_sizes.items():\n",
    "            print(f'{k} -> {k + 1}: {v[0]} x {v[1]}')\n",
    "        \n",
    "    def print_mapper(self, layer_index):\n",
    "        self.__layer_index_check(layer_index)\n",
    "        \n",
    "        print(f'W_{layer_index}: {layer_index} -> {layer_index + 1}')\n",
    "        print(self.model[layer_index])           \n",
    "            \n",
    "    def print_model(self):\n",
    "        print('Model:')\n",
    "        \n",
    "        for l in range(self.layers_num - 1):\n",
    "            print(f'W_{l}: {l} -> {l + 1}')\n",
    "            print(self.model[l])\n",
    "            \n",
    "    def print_delta(self, layer_index):\n",
    "        self.__layer_index_check(layer_index)\n",
    "        \n",
    "        print(self.deltas[layer_index])\n",
    "            \n",
    "    def print_deltas(self):\n",
    "        print('Deltas:')\n",
    "        \n",
    "        for l in range(self.layers_num):\n",
    "            print(f'delta_{l}:')\n",
    "            print(self.deltas[l])\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# UCITAVANJE PODATAKA I TESTIRANJE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "   sepal.length  sepal.width  petal.length  petal.width variety\n0           5.1          3.5           1.4          0.2  Setosa\n1           4.9          3.0           1.4          0.2  Setosa\n2           4.7          3.2           1.3          0.2  Setosa\n3           4.6          3.1           1.5          0.2  Setosa\n4           5.0          3.6           1.4          0.2  Setosa",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal.length</th>\n      <th>sepal.width</th>\n      <th>petal.length</th>\n      <th>petal.width</th>\n      <th>variety</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 63
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/iris.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Ukupan broj podataka: 150\nBroj atributa svakog podatka: 4\nAtributi: ['sepal.length', 'sepal.width', 'petal.length', 'petal.width']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "N = df.shape[0]\n",
    "print(f'Ukupan broj podataka: {N}')\n",
    "\n",
    "m = df.shape[1] - 1\n",
    "print(f'Broj atributa svakog podatka: {m}')\n",
    "\n",
    "attributes = list(df.drop('variety', axis=True).columns)\n",
    "print(f'Atributi: {attributes}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "     sepal.length  sepal.width  petal.length  petal.width     variety\n50            7.0          3.2           4.7          1.4  Versicolor\n51            6.4          3.2           4.5          1.5  Versicolor\n52            6.9          3.1           4.9          1.5  Versicolor\n53            5.5          2.3           4.0          1.3  Versicolor\n54            6.5          2.8           4.6          1.5  Versicolor\n55            5.7          2.8           4.5          1.3  Versicolor\n56            6.3          3.3           4.7          1.6  Versicolor\n57            4.9          2.4           3.3          1.0  Versicolor\n58            6.6          2.9           4.6          1.3  Versicolor\n59            5.2          2.7           3.9          1.4  Versicolor\n60            5.0          2.0           3.5          1.0  Versicolor\n61            5.9          3.0           4.2          1.5  Versicolor\n62            6.0          2.2           4.0          1.0  Versicolor\n63            6.1          2.9           4.7          1.4  Versicolor\n64            5.6          2.9           3.6          1.3  Versicolor\n65            6.7          3.1           4.4          1.4  Versicolor\n66            5.6          3.0           4.5          1.5  Versicolor\n67            5.8          2.7           4.1          1.0  Versicolor\n68            6.2          2.2           4.5          1.5  Versicolor\n69            5.6          2.5           3.9          1.1  Versicolor\n70            5.9          3.2           4.8          1.8  Versicolor\n71            6.1          2.8           4.0          1.3  Versicolor\n72            6.3          2.5           4.9          1.5  Versicolor\n73            6.1          2.8           4.7          1.2  Versicolor\n74            6.4          2.9           4.3          1.3  Versicolor\n75            6.6          3.0           4.4          1.4  Versicolor\n76            6.8          2.8           4.8          1.4  Versicolor\n77            6.7          3.0           5.0          1.7  Versicolor\n78            6.0          2.9           4.5          1.5  Versicolor\n79            5.7          2.6           3.5          1.0  Versicolor\n..            ...          ...           ...          ...         ...\n120           6.9          3.2           5.7          2.3   Virginica\n121           5.6          2.8           4.9          2.0   Virginica\n122           7.7          2.8           6.7          2.0   Virginica\n123           6.3          2.7           4.9          1.8   Virginica\n124           6.7          3.3           5.7          2.1   Virginica\n125           7.2          3.2           6.0          1.8   Virginica\n126           6.2          2.8           4.8          1.8   Virginica\n127           6.1          3.0           4.9          1.8   Virginica\n128           6.4          2.8           5.6          2.1   Virginica\n129           7.2          3.0           5.8          1.6   Virginica\n130           7.4          2.8           6.1          1.9   Virginica\n131           7.9          3.8           6.4          2.0   Virginica\n132           6.4          2.8           5.6          2.2   Virginica\n133           6.3          2.8           5.1          1.5   Virginica\n134           6.1          2.6           5.6          1.4   Virginica\n135           7.7          3.0           6.1          2.3   Virginica\n136           6.3          3.4           5.6          2.4   Virginica\n137           6.4          3.1           5.5          1.8   Virginica\n138           6.0          3.0           4.8          1.8   Virginica\n139           6.9          3.1           5.4          2.1   Virginica\n140           6.7          3.1           5.6          2.4   Virginica\n141           6.9          3.1           5.1          2.3   Virginica\n142           5.8          2.7           5.1          1.9   Virginica\n143           6.8          3.2           5.9          2.3   Virginica\n144           6.7          3.3           5.7          2.5   Virginica\n145           6.7          3.0           5.2          2.3   Virginica\n146           6.3          2.5           5.0          1.9   Virginica\n147           6.5          3.0           5.2          2.0   Virginica\n148           6.2          3.4           5.4          2.3   Virginica\n149           5.9          3.0           5.1          1.8   Virginica\n\n[100 rows x 5 columns]",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "attr1 = 'petal.length'\n",
    "attr2 = 'petal.width'\n",
    "attributes = [attr1, attr2]\n",
    "m = len(attributes)\n",
    "\n",
    "df_short = df[df['variety'] != 'Setosa']\n",
    "print(df_short)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Velicina skupa podataka: 100\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "N = df_short.shape[0]\n",
    "print(f'Velicina skupa podataka: {N}')\n",
    "\n",
    "X = np.ones((N, m + 1))\n",
    "X[:, 1] = df_short[attr1]\n",
    "X[:, 2] = df_short[attr2]\n",
    "\n",
    "y = df_short['variety']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Mapiranje imena klasa u numericke vrednosti:\nVersicolor -> 0\nVirginica -> 1\n\nMapiranje numerickih vrednosti u odgovarajuce nazive klasa:\n0 -> Versicolor\n1 -> Virginica\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "classes = df_short['variety'].unique()\n",
    "n_classes = len(classes)\n",
    "\n",
    "name_to_class_dict = dict(zip(classes, range(n_classes)))\n",
    "class_to_name_dict = dict(zip(range(n_classes), classes))\n",
    "\n",
    "print(f'Mapiranje imena klasa u numericke vrednosti:')\n",
    "for name, cls in name_to_class_dict.items():\n",
    "    print(f'{name} -> {cls}')\n",
    "\n",
    "print()\n",
    "print(f'Mapiranje numerickih vrednosti u odgovarajuce nazive klasa:')\n",
    "for cls, name in class_to_name_dict.items():\n",
    "    print(f'{cls} -> {name}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x9ec2978>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 68
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['red', 'blue']\n",
    "for c, cls in zip(colors, classes):\n",
    "    subsample = df.loc[df['variety'] == cls]\n",
    "    plt.scatter(subsample[attr1], subsample[attr2], color=c)\n",
    "    \n",
    "plt.xlabel(attr1)\n",
    "plt.ylabel(attr2)\n",
    "\n",
    "plt.legend(classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "y = y.replace(name_to_class_dict)\n",
    "y = np.array(y).reshape(-1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Podaci:\n[[1.  4.7 1.4]\n [1.  4.5 1.5]\n [1.  4.9 1.5]\n [1.  4.  1.3]\n [1.  4.6 1.5]\n [1.  4.5 1.3]\n [1.  4.7 1.6]\n [1.  3.3 1. ]\n [1.  4.6 1.3]\n [1.  3.9 1.4]]\n ...\nCiljne promenljive:\n[[0]\n [0]\n [0]\n [0]\n [0]\n [0]\n [0]\n [0]\n [0]\n [0]]\n ...\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(f'Podaci:')\n",
    "print(X[:10])\n",
    "print(' ...')\n",
    "\n",
    "print(f'Ciljne promenljive:')\n",
    "print(y[:10])\n",
    "print(' ...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "~ Neural network ~\nLayer 1:\n[1. 1. 1.]\nLayer 2:\n[1. 1. 1.]\nLayer 3:\n[1. 1. 1.]\nLayer 4:\n[1.]\n\nDimenzije matrica modela koji mapiraju slojeve:\n0 -> 1: 2 x 3\n1 -> 2: 2 x 3\n2 -> 3: 1 x 3\n\nModel:\nW_0: 0 -> 1\n[[ 0.2102487  -0.88563106 -0.65365835]\n [-0.68339839 -0.14446353 -0.42374298]]\nW_1: 1 -> 2\n[[-0.56786989  0.09544584 -0.83043103]\n [ 0.9486589   0.05803493  0.87375211]]\nW_2: 2 -> 3\n[[ 0.35733447 -0.42599028 -0.30439753]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# nn = NeuralNetwork(m, [3, 4], 1)\n",
    "nn = NeuralNetwork(m, [m, m], 1)\n",
    "nn.print_network()\n",
    "print()\n",
    "\n",
    "nn.print_layer_mapper_sizes()\n",
    "print()\n",
    "\n",
    "nn.set_model(nn.model * 100)\n",
    "nn.print_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "gradient (backpropagation):\n[-3.21192222e-05 -1.17424391e-04 -3.35939003e-05  2.50424302e-04\n  3.19164826e-04 -6.66990227e-05  6.04479300e-04 -2.51326576e-04\n -1.05879879e-03  4.85902877e-04 -1.52526381e-04 -6.34428875e-04\n -3.28064245e-03 -3.25706051e-03 -4.20061262e-04]\n\ngrad_approx (gradient checking):\n[-3.64463660e-06 -4.00002506e-06  9.12163702e-07  2.66483091e-03\n  1.80045051e-02  6.84055113e-03 -2.64959733e-01 -9.05423382e-02\n -1.90386663e-01  4.22175547e-02 -8.50266671e-05  2.83984053e-03\n  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n\nDifference:\n[2.84745856e-05 1.13424366e-04 3.45060640e-05 2.41440661e-03\n 1.76853402e-02 6.90725016e-03 2.65564213e-01 9.02910116e-02\n 1.89327865e-01 4.17316518e-02 6.74997140e-05 3.47426941e-03\n 3.28064245e-03 3.25706051e-03 4.20061262e-04]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "lambda_param = 0\n",
    "eps = 10e-2\n",
    "\n",
    "loss, gradient = nn.backward_propagation(X, y, lambda_param)\n",
    "grad_approx = gradient_checking(X, y, nn.model, lambda_param, eps)\n",
    "\n",
    "print('gradient (backpropagation):')\n",
    "print(gradient)\n",
    "print()\n",
    "\n",
    "print('grad_approx (gradient checking):')\n",
    "print(grad_approx)\n",
    "\n",
    "diff = abs(gradient - grad_approx)\n",
    "print('\\nDifference:')\n",
    "print(diff)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.fit(X, y, alpha=10e-6, plot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Istrenirani model: \nModel:\nW_0: 0 -> 1\n[[ 0.00519806 -0.00506938  0.00992735]\n [ 0.00331246  0.00680432  0.00422209]]\nW_1: 1 -> 2\n[[-0.00578401 -0.00185166 -0.00272882]\n [ 0.00419984 -0.00473241  0.00934449]]\nW_2: 2 -> 3\n[[-0.00578401 -0.00185166 -0.00272882]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(f'Istrenirani model: ')\n",
    "nn.print_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "petal_length = float(input('Unesite petal.length:'))\n",
    "petal_width = float(input('Unesite petal.width:'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "y_predict: 0.4979812610389185\nVersicolor\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = np.array([1, petal_length, petal_width])\n",
    "nn.predict(x, class_to_name_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# loss, gradient = nn.backward_propagation(X, y)\n",
    "# print(f'\\nLoss = {loss}')\n",
    "# print(f'\\nGradient:')\n",
    "# print(gradient)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# W_0 = np.array([[1, 1, 1, 1, 1, 1, 1], [2, 2, 2, 2, 2, 2, 2], [3, 3, 3, 3, 3, 3, 3]])\n",
    "# W_1 = np.array([[-1, -1, -1, -1], [-0.1, -0.2, -0.3, -0.4], [7, 7, 4, 4], [0, 2, 0, -3]])\n",
    "# W_2 = np.array([[5, 2, -5, -5, 10]])\n",
    "# # W_0 = np.array([[10, 1]])\n",
    "# # W_1 = np.array([[7, -10]])\n",
    "# \n",
    "# Ws = np.array([W_0, W_1, W_2])\n",
    "# nn.set_model(Ws)\n",
    "# nn.print_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.4979812610389185\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = np.array([1, 4.4, 3.2])\n",
    "y_predict = hypothesis_neural(nn.model, x)\n",
    "\n",
    "print(y_predict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[1 2 3 4]\n[1 2 3 4]\nPosle promene:\n[0 0 0]\n[1 2 3 4]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "b = a\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "a = np.array([0, 0, 0])\n",
    "\n",
    "print('Posle promene:')\n",
    "print(a)\n",
    "print(b)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}